{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Membership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below defines two **abstract classes**: the first represents a set and basic insert/search operations on it. You will need to impement this API four times, to implement (1) sequential search, (2) binary search tree, (3) balanced search tree, and (4) bloom filter. The second defines the synthetic data generator you will need to implement as part of your experimental framework. <br><br>**Do NOT modify the next cell** - use the dedicated cells further below for your implementation instead. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "\n",
    "from abc import ABC, abstractmethod  \n",
    "\n",
    "# abstract class to represent a set and its insert/search operations\n",
    "class AbstractSet(ABC):\n",
    "    \n",
    "    # constructor\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass           \n",
    "        \n",
    "    # inserts \"element\" in the set\n",
    "    # returns \"True\" after successful insertion, \"False\" if the element is already in the set\n",
    "    # element : str\n",
    "    # inserted : bool\n",
    "    @abstractmethod\n",
    "    def insertElement(self, element):     \n",
    "        inserted = False\n",
    "        return inserted   \n",
    "    \n",
    "    # checks whether \"element\" is in the set\n",
    "    # returns \"True\" if it is, \"False\" otherwise\n",
    "    # element : str\n",
    "    # found : bool\n",
    "    @abstractmethod\n",
    "    def searchElement(self, element):\n",
    "        found = False\n",
    "        return found    \n",
    "    \n",
    "    \n",
    "    \n",
    "# abstract class to represent a synthetic data generator\n",
    "class AbstractTestDataGenerator(ABC):\n",
    "    \n",
    "    # constructor\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass           \n",
    "        \n",
    "    # creates and returns a list of length \"size\" of strings\n",
    "    # size : int\n",
    "    # data : list<str>\n",
    "    @abstractmethod\n",
    "    def generateData(self, size):     \n",
    "        data = [\"\"]*size\n",
    "        return data   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below to define any auxiliary data structure and python function you may need. Leave the implementation of the main API to the next code cells instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD AUXILIARY DATA STRUCTURE DEFINITIONS AND HELPER CODE HERE\n",
    "\n",
    "# BST helper code:\n",
    "class NodeBST():    # The helper class for BST\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.right_node=None\n",
    "        self.left_node  = None\n",
    "      \n",
    "    def insert(self, value): \n",
    "        if value > self.value and self.right_node: \n",
    "            return self.right_node.insert(value)\n",
    "        elif value < self.value and self.left_node:\n",
    "            return self.left_node.insert(value)\n",
    "        elif value > self.value:\n",
    "            self.right_node = NodeBST(value)\n",
    "            return True\n",
    "        elif value < self.value:\n",
    "            self.left_node = NodeBST(value)\n",
    "            return True\n",
    "        return False\n",
    "      \n",
    "    def search(self, value):\n",
    "        if value > self.value and self.right_node:\n",
    "            return self.right_node.search(value)\n",
    "        elif value < self.value and self.left_node:\n",
    "            return self.left_node.search(value)\n",
    "        \n",
    "        elif (value == self.value):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def print_tree(self):  # prints from left to right\n",
    "        \n",
    "        print(self.value)\n",
    "        \n",
    "        if self.left_node:\n",
    "            self.left_node.print_tree()\n",
    "            \n",
    "        if self.right_node:\n",
    "            self.right_node.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced Tree helper code\n",
    "\n",
    "class BalancedNode:\n",
    "    def __init__(self, value):\n",
    "        self.left = None\n",
    "        self.parent = None\n",
    "        self.right = None\n",
    "        self.value = value\n",
    "        self.colour = \"R\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linked list implementation of sequential search\n",
    "\n",
    "class Node_linked_list:\n",
    "    def __init__(self, data=None, next=None): \n",
    "        self.data = data\n",
    "        self.next = next\n",
    "\n",
    "class SequentialSearchSetLinkedList(AbstractSet):\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "\n",
    "    \n",
    "    def insertElement(self, element):\n",
    "        if self.head is None:\n",
    "            self.head = Node_linked_list(element, None)\n",
    "            return\n",
    "            \n",
    "        \n",
    "        node = self.head\n",
    "        while node.next is not None:\n",
    "            node = node.next\n",
    "        \n",
    "        node.next = Node_linked_list(element, None)\n",
    "\n",
    "\n",
    "    def searchElement(self, element):\n",
    "        search_node = self.head\n",
    "        while search_node is not None:\n",
    "            if search_node.data == element:\n",
    "                return True\n",
    "            search_node = search_node.next\n",
    "        return False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below to implement the requested API by means of **sequential search**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialSearchSet(AbstractSet):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.words = []\n",
    "                \n",
    "    def insertElement(self, element):\n",
    "        inserted = False\n",
    "        for value in self.words:\n",
    "            if value == element:\n",
    "                return inserted\n",
    "        self.words.append(element)\n",
    "        inserted = True\n",
    "      \n",
    "        return inserted\n",
    "    \n",
    "\n",
    "    def searchElement(self, element):\n",
    "        \n",
    "        found = False\n",
    "        for value in self.words:\n",
    "            if value == element:\n",
    "                found = True\n",
    "                return found\n",
    "        \n",
    "        return found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below to implement the requested API by means of **binary search tree**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper class for the binary search tree \n",
    "\n",
    "class BinarySearchTreeSet(AbstractSet):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.root = NodeBST(\"0\")\n",
    "        \n",
    "    def insertElement(self, element):\n",
    "        inserted = False\n",
    "        inserted = self.root.insert(element)\n",
    "        return inserted\n",
    "\n",
    "    def searchElement(self, element):     \n",
    "        found = False\n",
    "        found = self.root.search(element)\n",
    "        return found    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below to implement the requested API by means of **balanced search tree**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BalancedSearchTreeSet(AbstractSet):\n",
    "    def __init__(self): # code to initialize the tree structure \n",
    "        self.empty = BalancedNode(\"\")\n",
    "        self.empty.colour = \"B\"\n",
    "        self.empty.left = None\n",
    "        self.empty.right = None\n",
    "        self.root = self.empty\n",
    "        \n",
    "\n",
    "    def insertElement(self, element): \n",
    "        # This function adds the node to be inserted like a binary tree\n",
    "        # It gives it the initial colour of red, but if it is the root it changes the colour to black\n",
    "        # Returns inserted if no further operations are needed (best case scenario), otherwise calls another function\n",
    "        inserted = False\n",
    "        node = BalancedNode(element)\n",
    "        node.parent = None\n",
    "        node.value = element\n",
    "        node.colour = \"R\"\n",
    "        node.left = self.empty\n",
    "        node.right = self.empty\n",
    "\n",
    "        tempval = None\n",
    "        rt = self.root\n",
    "\n",
    "        check = self.searchElement(element)\n",
    "        if check==True:\n",
    "            inserted = False\n",
    "            return inserted\n",
    "\n",
    "        while rt != self.empty:\n",
    "            tempval = rt\n",
    "            if node.value < rt.value:\n",
    "                rt = rt.left\n",
    "            else:\n",
    "                rt = rt.right\n",
    "\n",
    "        node.parent = tempval\n",
    "\n",
    "        if tempval == None:\n",
    "            self.root = node\n",
    "        elif node.value < tempval.value:\n",
    "            tempval.left = node\n",
    "        else:\n",
    "            tempval.right = node\n",
    "\n",
    "        if node.parent == None:\n",
    "            node.colour = \"B\"\n",
    "            inserted = True\n",
    "            return inserted\n",
    "\n",
    "        if node.parent.parent == None:\n",
    "            inserted = True\n",
    "            return inserted\n",
    "\n",
    "        self.insertcontinue(node)\n",
    "        return inserted\n",
    "\n",
    "    def search(self, node, value):\n",
    "        # Searches similarly to a binary tree\n",
    "        found = False\n",
    "        if node == self.empty:\n",
    "            return found\n",
    "        elif value == node.value:\n",
    "            found = True\n",
    "            return found\n",
    "        if value < node.value:\n",
    "            return self.search(node.left, value)\n",
    "        return self.search(node.right, value)\n",
    "\n",
    "    def leftrotate(self, rotateval):\n",
    "        # Rotates the tree to the left around a particular node\n",
    "        rchild = rotateval.right\n",
    "        rotateval.right = rchild.left\n",
    "        if rchild.left != self.empty:\n",
    "            rchild.left.parent = rotateval\n",
    "        rchild.parent = rotateval.parent\n",
    "        if rotateval.parent == None:\n",
    "            self.root = rchild\n",
    "        elif rotateval == rotateval.parent.left:\n",
    "            rotateval.parent.left = rchild\n",
    "        else:\n",
    "            rotateval.parent.right = rchild\n",
    "        rchild.left = rotateval\n",
    "        rotateval.parent = rchild\n",
    "\n",
    "    def rightrotate(self, rotateval):\n",
    "        # Rotates the tree to the right around a particular node\n",
    "        lchild = rotateval.left\n",
    "        rotateval.left = lchild.right\n",
    "        if lchild.right != self.empty:\n",
    "            lchild.right.parent = rotateval\n",
    "        lchild.parent = rotateval.parent\n",
    "        if rotateval.parent == None:\n",
    "            self.root = lchild\n",
    "        elif rotateval == rotateval.parent.right:\n",
    "            rotateval.parent.right = lchild\n",
    "        else:\n",
    "            rotateval.parent.left = lchild\n",
    "        lchild.right = rotateval\n",
    "        rotateval.parent = lchild\n",
    "\n",
    "    def colourswap(self, a, l):\n",
    "        # If called, this changes the colour of the grandparent of the node being colourswapped to RED\n",
    "        # It also changes the colour of the aunt and the parent to BLACK\n",
    "        if a.colour == \"R\":\n",
    "            a.colour = \"B\"\n",
    "            l.parent.colour = \"B\"\n",
    "            l.parent.parent.colour = \"R\"\n",
    "            l = l.parent.parent\n",
    "\n",
    "    def insertcontinue(self, leaf):\n",
    "        # This function is only called if there are 2 red nodes adjacent to one another\n",
    "        # It then locates the aunt, and depending on the aunts colour it performs actions to self-balance itself\n",
    "        while leaf.parent.colour == \"R\":\n",
    "            if leaf.parent == leaf.parent.parent.right:\n",
    "                # This line differentiates the left and right subtrees of the main root\n",
    "                aunt = leaf.parent.parent.left\n",
    "                if aunt.colour == \"R\":\n",
    "                    # If the aunt is red, a colourswap is conducted\n",
    "                    self.colourswap(aunt, leaf)\n",
    "                    leaf = leaf.parent.parent\n",
    "                else:\n",
    "                    #Otherwise, a right-left rotation is conducted\n",
    "                    if leaf == leaf.parent.left:\n",
    "                        leaf = leaf.parent\n",
    "                        self.rightrotate(leaf)\n",
    "                    leaf.parent.colour = \"B\"\n",
    "                    leaf.parent.parent.colour = \"R\"\n",
    "                    self.leftrotate(leaf.parent.parent)\n",
    "            else:\n",
    "                # This section operates with the right subtree of the main root\n",
    "                aunt = leaf.parent.parent.right\n",
    "                if aunt.colour == \"R\":\n",
    "                    self.colourswap(aunt, leaf)\n",
    "                    leaf = leaf.parent.parent\n",
    "                else:\n",
    "                    # If the aunt is black, then a left-right rotation is conducted\n",
    "                    if leaf == leaf.parent.right:\n",
    "                        leaf = leaf.parent\n",
    "                        self.leftrotate(leaf)\n",
    "                    leaf.parent.colour = \"B\"\n",
    "                    leaf.parent.parent.colour = \"R\"\n",
    "                    self.rightrotate(leaf.parent.parent)\n",
    "            if leaf == self.root:\n",
    "                break\n",
    "            self.root.colour = \"B\"\n",
    "\n",
    "           \n",
    "\n",
    "    def searchElement(self, element):\n",
    "        #This initializes the search function from the root\n",
    "        return self.search(self.root, element)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below to implement the requested API by means of **bloom filter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BloomFilterSet(AbstractSet):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.size = 100000000\n",
    "        self.hash_count = 3\n",
    "        self.bit_array = [0] * self.size\n",
    "        self.hash_functions = self.generate_hash_functions()\n",
    "    \n",
    "    def generate_hash_functions(self): # Code to generate a list of unique hash functions\n",
    "            hash_fuctions = []\n",
    "            for i in range(1,self.hash_count+1):\n",
    "                hash_fuctions.append(self.generate_hash_function(i))\n",
    "            return hash_fuctions\n",
    "    \n",
    "    def generate_hash_function(self,seed): # Code to generate a unique hash function based on an inputed seed value\n",
    "        def hash_function(value):\n",
    "            return (hash(value + str(seed)) % self.size)\n",
    "        return hash_function\n",
    "        \n",
    "    def insertElement(self, element):\n",
    "        inserted = False\n",
    "        for hash_function in self.hash_functions:\n",
    "            if (self.bit_array[hash_function(element)] == 0):\n",
    "                self.bit_array[hash_function(element)] = 1\n",
    "                inserted = True\n",
    "        return inserted\n",
    "\n",
    "    def searchElement(self, element):     \n",
    "        found = False\n",
    "        # ADD YOUR CODE HERE\n",
    "        for hash_function in self.hash_functions:\n",
    "            if self.bit_array[hash_function(element)] == 0:\n",
    "                return found\n",
    "        found = True\n",
    "        return found    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below to implement the **synthetic data generator** as part of your experimental framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "class TestDataGenerator(AbstractTestDataGenerator):\n",
    "    \n",
    "    def __init__(self, punctuation=False, length=7, lower=True, upper=True, digits=True):\n",
    "        self.length = length\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        self.digits = digits\n",
    "        self.punctuation = punctuation\n",
    "\n",
    "    def getCharacters(self):\n",
    "        character = ''\n",
    "        if self.lower:\n",
    "            character += string.ascii_lowercase\n",
    "        if self.upper:\n",
    "            character += string.ascii_uppercase\n",
    "        if self.digits:\n",
    "            character += string.digits\n",
    "        if self.punctuation:\n",
    "            character += string.punctuation\n",
    "\n",
    "        return character\n",
    "\n",
    "        \n",
    "    def generateData(self, size):     # random string generator, size defines the amount of data that is going to be generated\n",
    "        data = []\n",
    "        characters = self.getCharacters()\n",
    "\n",
    "        for i in range(size):\n",
    "            data.append(''.join(random.choices(characters, k=random.randint(3,self.length))))\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def generateSorted(self, size):     # this is the worst case scenario for BST and balanced, as it creates linear tree for BST and most operations for balanced\n",
    "        return sorted(self.generateData(size))\n",
    "    \n",
    "    def generateReverseSorted(self, size):  \n",
    "        return sorted(self.generateData(size), reverse=True) \n",
    "    \n",
    "    def generateBestCaseBinary(self, size):\n",
    "        class Node:\n",
    "            def __init__(self, value):\n",
    "                self.value = value\n",
    "                self.left = None\n",
    "                self.right = None\n",
    "\n",
    "        class Queue:    # Queue API, needed to use breadth-first-search to generate median sorted data, which needs queue in the beginning.\n",
    "            def __init__(self):\n",
    "                self.items = []\n",
    "\n",
    "            def is_empty(self):\n",
    "                return len(self.items) == 0\n",
    "\n",
    "            def enqueue(self, item):\n",
    "                self.items.append(item)\n",
    "\n",
    "            def dequeue(self):\n",
    "                return self.items.pop(0)\n",
    "\n",
    "        def build_balanced_bst(strings): #Builds the BST from the sorted strings so that it will be perfectly balanced, uses binary-search like approach\n",
    "            if not strings:\n",
    "                return None\n",
    "            \n",
    "            mid = len(strings) // 2\n",
    "            root = Node(strings[mid])\n",
    "            root.left = build_balanced_bst(strings[:mid])\n",
    "            root.right = build_balanced_bst(strings[mid+1:])\n",
    "            return root\n",
    "\n",
    "        def generate_balanced_bst_data():   #With the usage of breadth-first-search, scans the tree layer by layer and then outputs median sorted data.\n",
    "            result = []\n",
    "            root = build_balanced_bst(self.generateSorted(size))\n",
    "\n",
    "            # Output BST layer by layer\n",
    "            queue = Queue()\n",
    "            queue.enqueue(root)\n",
    "            current_level = 1\n",
    "            next_level = 0\n",
    "            while not queue.is_empty():\n",
    "                node = queue.dequeue()\n",
    "                result.append(node.value)\n",
    "                current_level -= 1\n",
    "                \n",
    "                if node.left:\n",
    "                    queue.enqueue(node.left)\n",
    "                    next_level += 1\n",
    "                if node.right:\n",
    "                    queue.enqueue(node.right)\n",
    "                    next_level += 1\n",
    "                \n",
    "                if current_level == 0:\n",
    "                    current_level = next_level\n",
    "                    next_level = 0\n",
    "            return result\n",
    "\n",
    "        return generate_balanced_bst_data()\n",
    "    \n",
    "    def generateDuplicateData(self, size):\n",
    "        values = self.generateData(10)\n",
    "        data = []\n",
    "        for count in range(size):\n",
    "            randvalue = random.randint(0,9)\n",
    "            data.append(values[randvalue])\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cells below for the python code needed to **fully evaluate your implementations**, first on real data and subsequently on synthetic data (i.e., read data from test files / generate synthetic one, instantiate each of the 4 set implementations in turn, then thorouhgly experiment with insert/search operations and measure their performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "# ADD YOUR TEST CODE HERE TO WORK ON REAL DATA\n",
    "iterations= 1\n",
    "\n",
    "datastuctures = {\"bloomfilter\": BloomFilterSet,\"bst\": BinarySearchTreeSet, \"balanced_tree\": BalancedSearchTreeSet, \"seq_search\":SequentialSearchSet}\n",
    "created_dst={}\n",
    "\n",
    "def insert(key, file):\n",
    "    data_structure = datastuctures[key]()\n",
    "    for line in file:\n",
    "        for word in line.split():\n",
    "            data_structure.insertElement(word)\n",
    "    created_dst[key] = data_structure\n",
    "\n",
    "def search(key, file):\n",
    "        for word in file:\n",
    "            dst = created_dst[key]\n",
    "            word = word.strip()\n",
    "            if (dst.searchElement(word)):\n",
    "                pass\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "def test():\n",
    "    for key in datastuctures:\n",
    "        with open(\"./testfiles/test1-mobydick.txt\", \"r\") as file:    #Testing search and insert on file 1\n",
    "            time= timeit.timeit(lambda: insert(key, file), number=iterations)\n",
    "            print(\"Inserting file 1 into \" + key + \" took \" + str(time/iterations) + \" seconds\")\n",
    "        with open(\"./testfiles/test-search.txt\", \"r\") as file:\n",
    "            time = timeit.timeit(lambda: search(key, file), number=iterations)\n",
    "            print(\"Searching file 1 in \" + key + \" took \" + str(time/iterations) + \" seconds\")\n",
    "        print(\"____________________________________________________\")\n",
    "    for key in datastuctures:\n",
    "        with open(\"./testfiles/test2-warpeace.txt\", \"r\") as file:   #Testing search and insert on file 2\n",
    "                time = timeit.timeit(lambda: insert(key, file), number=iterations)\n",
    "                print(\"Inserting file 2 into \" + key + \" took \" + str(time/iterations) + \" seconds\")\n",
    "        with open(\"./testfiles/test-search.txt\", \"r\") as file:\n",
    "                time = timeit.timeit(lambda: search(key, file), number=iterations)\n",
    "                print(\"Searching file 2 in \" + key + \" took \" + str(time/iterations) + \" seconds\")\n",
    "        print(\"____________________________________________________\")\n",
    "    for key in datastuctures:\n",
    "        with open(\"./testfiles/test3-dickens.txt\", \"r\") as file:     #Testing search and insert on file 3\n",
    "                time = timeit.timeit(lambda: insert(key, file), number=iterations)\n",
    "                print(\"Inserting file 3 into \" + key + \" took \" + str(time/iterations) + \" seconds\")\n",
    "        with open(\"./testfiles/test-search.txt\", \"r\") as file:\n",
    "                time = timeit.timeit(lambda: search(key, file), number=iterations)\n",
    "                print(\"Searching file 3 in \" + key + \" took \" + str(time/iterations) + \" seconds\")\n",
    "        print(\"____________________________________________________\")\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "# ADD YOUR TEST CODE HERE TO WORK ON SYNTHETIC DATA\n",
    "import random\n",
    "iterations= 1\n",
    "data_generator = TestDataGenerator(length=5)\n",
    "datastuctures = {\"bloomfilter\": BloomFilterSet, \"balanced_tree\": BalancedSearchTreeSet, \"bst\": BinarySearchTreeSet, \"seq_search\":SequentialSearchSet}\n",
    "test_type = {\"unsorted\":data_generator.generateData, \"sorted\":data_generator.generateSorted  ,\"median\": data_generator.generateBestCaseBinary, \"rev_sorted\": data_generator.generateReverseSorted}\n",
    "created_dst={}\n",
    "count = 3000\n",
    "step =50\n",
    "\n",
    "def insert(key, list):    #Inserting data into data structure\n",
    "    data_structure = datastuctures[key]()\n",
    "    for word in list:\n",
    "            data_structure.insertElement(word)\n",
    "    created_dst[key] = data_structure\n",
    "\n",
    "def search(key, list):   #Searching data in data structure\n",
    "    for word in list:\n",
    "        dst = created_dst[key]\n",
    "        if (dst.searchElement(word)):\n",
    "            pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def test_unsorted():   #Testing random data\n",
    "    times_insert={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    times_search={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    for i in range(1000,count, step):\n",
    "        list = data_generator.generateData(i)\n",
    "        search_list = list.copy()\n",
    "        random.shuffle(search_list)\n",
    "        search_word = search_list[0]\n",
    "        for key in datastuctures:\n",
    "            insertion_time = timeit.timeit(lambda: insert(key, list), number=iterations)\n",
    "            times_insert[key].append(insertion_time/(iterations))\n",
    "            print(\"Inserting strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "            search_time = timeit.timeit(lambda: created_dst[key].searchElement(search_word), number=10)\n",
    "            print(\"Searching strings of size \" + str(i) + \" into \" + key + \" took \" + str(search_time/10) + \" seconds\")\n",
    "            times_search[key].append(search_time/(10))\n",
    "            print(\"____________________________________________________\")\n",
    "test_unsorted()      \n",
    "print(\"____________________________________________________\")\n",
    "\n",
    "\n",
    "def test_sorted():  #Testing sorted data\n",
    "    times_insert={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    times_search={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    for i in range(100,count, step):\n",
    "        list = data_generator.generateSorted(i)\n",
    "        search_list = list.copy()\n",
    "        random.shuffle(search_list)\n",
    "        search_word = list[len(search_list)-1]\n",
    "        for key in datastuctures:\n",
    "            insertion_time = timeit.timeit(lambda: insert(key, list), number=iterations)\n",
    "            times_insert[key].append(insertion_time/iterations)\n",
    "            print(\"Inserting strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "            search_time = timeit.timeit(lambda: created_dst[key].searchElement(search_word), number=10)\n",
    "            print(\"Searching strings of size \" + str(i) + \" into \" + key + \" took \" + str(search_time/10) + \" seconds\")\n",
    "            times_search[key].append(search_time/10)\n",
    "            print(\"____________________________________________________\")\n",
    "    print(times_insert, times_search)\n",
    "test_sorted()\n",
    "print(\"____________________________________________________\")\n",
    "\n",
    "def test_reverse_sorted(): #Testing reverse sorted data\n",
    "    times_insert={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    times_search={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    for i in range(100,count, step):\n",
    "        list = data_generator.generateReverseSorted(i)\n",
    "        search_list = list.copy()\n",
    "        random.shuffle(search_list)\n",
    "        search_word = list[len(search_list)-1]\n",
    "        for key in datastuctures:\n",
    "            insertion_time = timeit.timeit(lambda: insert(key, list), number=iterations)\n",
    "            times_insert[key].append(insertion_time/iterations)\n",
    "            print(\"Inserting strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "            search_time = timeit.timeit(lambda: created_dst[key].searchElement(search_word), number=10)\n",
    "            print(\"Searching strings of size \" + str(i) + \" into \" + key + \" took \" + str(search_time/10) + \" seconds\")\n",
    "            times_search[key].append(search_time/10)\n",
    "            print(\"____________________________________________________\")\n",
    "test_reverse_sorted()\n",
    "print(\"____________________________________________________\")\n",
    "\n",
    "def test_median_binary(): #Testing median binary data(best binary tree data)\n",
    "    times_insert={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    times_search={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    for i in range(100,count, step):\n",
    "        list = data_generator.generateBestCaseBinary(i)\n",
    "        search_list = list.copy()\n",
    "        random.shuffle(search_list)\n",
    "        search_word = search_list[len(search_list)//2]\n",
    "        for key in datastuctures:\n",
    "            insertion_time = timeit.timeit(lambda: insert(key, list), number=iterations)\n",
    "            times_insert[key].append(insertion_time/iterations)\n",
    "            print(\"Inserting strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "            search_time = timeit.timeit(lambda: created_dst[key].searchElement(search_word), number=10)\n",
    "            print(\"Searching strings of size \" + str(i) + \" into \" + key + \" took \" + str(search_time/10) + \" seconds\")\n",
    "            times_search[key].append(search_time/10)\n",
    "            print(\"____________________________________________________\")\n",
    "test_median_binary()\n",
    "print(\"____________________________________________________\")\n",
    "\n",
    "def test_duplicates():  #Testing duplicate data\n",
    "    times_insert={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    times_search={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    for i in range(100,count, step):\n",
    "        list = data_generator.generateDuplicateData(i)\n",
    "        search_list = list.copy()\n",
    "        random.shuffle(search_list)\n",
    "        for key in datastuctures:\n",
    "            insertion_time = timeit.timeit(lambda: insert(key, list), number=iterations)\n",
    "            times_insert[key].append(insertion_time/iterations)\n",
    "            print(\"Inserting strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "            search_time = timeit.timeit(lambda: search(key, search_list), number=iterations)\n",
    "            print(\"Searching strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "            times_search[key].append(search_time/iterations)\n",
    "            print(\"____________________________________________________\")\n",
    "test_duplicates()\n",
    "print(\"____________________________________________________\")\n",
    "\n",
    "def test_per_dst():  #Testing all data types for each data structure\n",
    "    for key in datastuctures:\n",
    "        times_insert={\"unsorted\":[], \"sorted\":[]  ,\"median\": [], \"rev_sorted\":[]}\n",
    "        times_search={\"unsorted\":[], \"sorted\":[]  ,\"median\": [], \"rev_sorted\":[]}\n",
    "        for i in range(100,count, step):\n",
    "            for test in test_type:\n",
    "                list = test_type[test](i)\n",
    "                search_list = list.copy()\n",
    "                random.shuffle(search_list)\n",
    "                insertion_time = timeit.timeit(lambda: insert(key, list), number=iterations)\n",
    "                times_insert[test].append(insertion_time/iterations)\n",
    "                print(\"Inserting \" + str(test)+ \" strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "                search_time = timeit.timeit(lambda: search(key, search_list), number=iterations)\n",
    "                print(\"Searching \" + str(test)+ \" strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "                times_search[test].append(search_time/iterations)\n",
    "                print(\"____________________________________________________\")\n",
    "test_per_dst()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def graph(data, title,start,stop,step):\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"size of input\")\n",
    "    plt.ylabel(\"time in seconds\")\n",
    "    for key in data:\n",
    "        plt.plot([i for i in range(start,stop, step)], data[key], label=key)\n",
    "        plt.scatter([i for i in range(start,stop, step)], data[key] , label=key)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "# ADD YOUR TEST CODE HERE TO WORK ON SYNTHETIC DATA\n",
    "import random\n",
    "iterations= 1\n",
    "data_generator = TestDataGenerator(length=5)\n",
    "datastuctures = {\"bloomfilter\": BloomFilterSet, \"balanced_tree\": BalancedSearchTreeSet, \"bst\": BinarySearchTreeSet, \"seq_search\":SequentialSearchSet}\n",
    "test_type = {\"unsorted\":data_generator.generateData, \"sorted\":data_generator.generateSorted  ,\"median\": data_generator.generateBestCaseBinary, \"rev_sorted\": data_generator.generateReverseSorted}\n",
    "created_dst={}\n",
    "count = 3000\n",
    "step =50\n",
    "\n",
    "def insert(key, list):    #Inserting data into data structure\n",
    "    data_structure = datastuctures[key]()\n",
    "    for word in list:\n",
    "            data_structure.insertElement(word)\n",
    "    created_dst[key] = data_structure\n",
    "\n",
    "def search(key, list):   #Searching data in data structure\n",
    "    for word in list:\n",
    "        dst = created_dst[key]\n",
    "        if (dst.searchElement(word)):\n",
    "            pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def test_unsorted():   #Testing random data\n",
    "    times_insert={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    times_search={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    for i in range(1000,count, step):\n",
    "        list = data_generator.generateData(i)\n",
    "        search_list = list.copy()\n",
    "        random.shuffle(search_list)\n",
    "        search_word = search_list[0]\n",
    "        for key in datastuctures:\n",
    "            insertion_time = timeit.timeit(lambda: insert(key, list), number=iterations)\n",
    "            times_insert[key].append(insertion_time/(iterations))\n",
    "            print(\"Inserting strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "            search_time = timeit.timeit(lambda: created_dst[key].searchElement(search_word), number=10)\n",
    "            print(\"Searching strings of size \" + str(i) + \" into \" + key + \" took \" + str(search_time/10) + \" seconds\")\n",
    "            times_search[key].append(search_time/(10))\n",
    "            print(\"____________________________________________________\")\n",
    "    graph(times_insert, \"insert with unsorted data\",1000,count,step)\n",
    "    graph(times_search, \"search with unsorted data\",1000, count, step)\n",
    "test_unsorted()      \n",
    "print(\"____________________________________________________\")\n",
    "\n",
    "\n",
    "def test_sorted():  #Testing sorted data\n",
    "    times_insert={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    times_search={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    for i in range(100,count, step):\n",
    "        list = data_generator.generateSorted(i)\n",
    "        search_list = list.copy()\n",
    "        random.shuffle(search_list)\n",
    "        search_word = list[len(search_list)-1]\n",
    "        for key in datastuctures:\n",
    "            insertion_time = timeit.timeit(lambda: insert(key, list), number=iterations)\n",
    "            times_insert[key].append(insertion_time/iterations)\n",
    "            print(\"Inserting strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "            search_time = timeit.timeit(lambda: created_dst[key].searchElement(search_word), number=10)\n",
    "            print(\"Searching strings of size \" + str(i) + \" into \" + key + \" took \" + str(search_time/10) + \" seconds\")\n",
    "            times_search[key].append(search_time/10)\n",
    "            print(\"____________________________________________________\")\n",
    "    print(times_insert, times_search)\n",
    "    graph(times_insert, \"insert with sorted data\",100,count, step)\n",
    "    graph(times_search, \"search with sorted data\",100,count, step)\n",
    "test_sorted()\n",
    "print(\"____________________________________________________\")\n",
    "\n",
    "def test_reverse_sorted(): #Testing reverse sorted data\n",
    "    times_insert={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    times_search={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    for i in range(100,count, step):\n",
    "        list = data_generator.generateReverseSorted(i)\n",
    "        search_list = list.copy()\n",
    "        random.shuffle(search_list)\n",
    "        search_word = list[len(search_list)-1]\n",
    "        for key in datastuctures:\n",
    "            insertion_time = timeit.timeit(lambda: insert(key, list), number=iterations)\n",
    "            times_insert[key].append(insertion_time/iterations)\n",
    "            print(\"Inserting strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "            search_time = timeit.timeit(lambda: created_dst[key].searchElement(search_word), number=10)\n",
    "            print(\"Searching strings of size \" + str(i) + \" into \" + key + \" took \" + str(search_time/10) + \" seconds\")\n",
    "            times_search[key].append(search_time/10)\n",
    "            print(\"____________________________________________________\")\n",
    "    graph(times_insert, \"insert with reverse sorted data\",100,count, step)\n",
    "    graph(times_search, \"search with reverse sorted data\",100,count, step)\n",
    "test_reverse_sorted()\n",
    "print(\"____________________________________________________\")\n",
    "\n",
    "def test_median_binary(): #Testing median binary data(best binary tree data)\n",
    "    times_insert={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    times_search={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    for i in range(100,count, step):\n",
    "        list = data_generator.generateBestCaseBinary(i)\n",
    "        search_list = list.copy()\n",
    "        random.shuffle(search_list)\n",
    "        search_word = search_list[len(search_list)//2]\n",
    "        for key in datastuctures:\n",
    "            insertion_time = timeit.timeit(lambda: insert(key, list), number=iterations)\n",
    "            times_insert[key].append(insertion_time/iterations)\n",
    "            print(\"Inserting strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "            search_time = timeit.timeit(lambda: created_dst[key].searchElement(search_word), number=10)\n",
    "            print(\"Searching strings of size \" + str(i) + \" into \" + key + \" took \" + str(search_time/10) + \" seconds\")\n",
    "            times_search[key].append(search_time/10)\n",
    "            print(\"____________________________________________________\")\n",
    "    graph(times_insert, \"insert with median sorted data\",100,count, step)\n",
    "    graph(times_search, \"search with median sorted data\",100,count, step)\n",
    "test_median_binary()\n",
    "print(\"____________________________________________________\")\n",
    "\n",
    "def test_duplicates():  #Testing duplicate data\n",
    "    times_insert={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    times_search={\"bloomfilter\":[], \"balanced_tree\":[]  ,\"bst\": [], \"seq_search\":[]}\n",
    "    for i in range(100,count, step):\n",
    "        list = data_generator.generateDuplicateData(i)\n",
    "        search_list = list.copy()\n",
    "        random.shuffle(search_list)\n",
    "        for key in datastuctures:\n",
    "            insertion_time = timeit.timeit(lambda: insert(key, list), number=iterations)\n",
    "            times_insert[key].append(insertion_time/iterations)\n",
    "            print(\"Inserting strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "            search_time = timeit.timeit(lambda: search(key, search_list), number=iterations)\n",
    "            print(\"Searching strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "            times_search[key].append(search_time/iterations)\n",
    "            print(\"____________________________________________________\")\n",
    "    graph(times_insert, \"insert with duplicates data\",100,count, step)\n",
    "    graph(times_search, \"search with duplicates data\",100,count, step)\n",
    "test_duplicates()\n",
    "print(\"____________________________________________________\")\n",
    "\n",
    "def test_per_dst():  #Testing all data types for each data structure\n",
    "    for key in datastuctures:\n",
    "        times_insert={\"unsorted\":[], \"sorted\":[]  ,\"median\": [], \"rev_sorted\":[]}\n",
    "        times_search={\"unsorted\":[], \"sorted\":[]  ,\"median\": [], \"rev_sorted\":[]}\n",
    "        for i in range(100,count, step):\n",
    "            for test in test_type:\n",
    "                list = test_type[test](i)\n",
    "                search_list = list.copy()\n",
    "                random.shuffle(search_list)\n",
    "                insertion_time = timeit.timeit(lambda: insert(key, list), number=iterations)\n",
    "                times_insert[test].append(insertion_time/iterations)\n",
    "                print(\"Inserting \" + str(test)+ \" strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "                search_time = timeit.timeit(lambda: search(key, search_list), number=iterations)\n",
    "                print(\"Searching \" + str(test)+ \" strings of size \" + str(i) + \" into \" + key + \" took \" + str(insertion_time/iterations) + \" seconds\")\n",
    "                times_search[test].append(search_time/iterations)\n",
    "                print(\"____________________________________________________\")\n",
    "        graph(times_insert, \"insert with \"+ str(key),100,count,step)\n",
    "        graph(times_search, \"search with  \"+ str(key),100,count,step)\n",
    "test_per_dst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert(data_structure, list):\n",
    "    for word in list:\n",
    "            data_structure.insertElement(word)\n",
    "\n",
    "def search(dst, list):\n",
    "    for word in list:\n",
    "        if (dst.searchElement(word)):\n",
    "            pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "class BloomFilterSettest(AbstractSet):\n",
    "    \n",
    "    def __init__(self,hash_count,size):\n",
    "        # ADD YOUR CODE HERE\n",
    "        self.size = size\n",
    "        self.hash_count = hash_count\n",
    "        self.bit_array = [0] * self.size\n",
    "        self.hash_functions = self.generate_hash_functions()\n",
    "    \n",
    "    def generate_hash_functions(self): # Code to generate a list of unique hash functions\n",
    "            hash_fuctions = []\n",
    "            for i in range(1,self.hash_count+1):\n",
    "                hash_fuctions.append(self.generate_hash_function(i))\n",
    "            return hash_fuctions\n",
    "    \n",
    "    def generate_hash_function(self,seed): # Code to generate a unique hash function based on an inputed seed value\n",
    "        def hash_function(value):\n",
    "            return hash(value + str(seed)) % self.size\n",
    "        return hash_function\n",
    "        \n",
    "    def insertElement(self, element):\n",
    "        inserted = False\n",
    "        # ADD YOUR CODE HERE\n",
    "        for hash_function in self.hash_functions:\n",
    "            self.bit_array[hash_function(element)] = 1\n",
    "        inserted = True\n",
    "        \n",
    "        return inserted\n",
    "\n",
    "    def searchElement(self, element):     \n",
    "        found = False\n",
    "        # ADD YOUR CODE HERE\n",
    "        for hash_function in self.hash_functions:\n",
    "            if self.bit_array[hash_function(element)] == 0:\n",
    "                return found\n",
    "        found = True\n",
    "        return found    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "data_size = 1000\n",
    "count = data_size\n",
    "iterations = 1\n",
    "\n",
    "def test_bloom_size():  #Testing peroformance of bloom filter with different sizes\n",
    "    data_generator= TestDataGenerator()\n",
    "    sizes = [str(i) for i in range(10000,10000000,10000)]\n",
    "    times_insert=[]\n",
    "    times_search=[]\n",
    "    list = data_generator.generateData(1000)\n",
    "    search_list = list.copy()\n",
    "    random.shuffle(search_list)\n",
    "    search_word = search_list[0]\n",
    "    for size in sizes:\n",
    "        bf = BloomFilterSettest(1,int(size))\n",
    "        insert_time = timeit.timeit(lambda: insert(bf, list), number=iterations)\n",
    "        times_insert.append(insert_time/iterations)\n",
    "        print(\"Inserting into bloom filter of size \" + size + \" took \" + str(insert_time/iterations) + \" seconds\")\n",
    "        search_time = timeit.timeit(lambda: bf.searchElement(search_word), number=10)\n",
    "        print(\"Searching into bloom filter of size \" + size + \" took \" + str(search_time/10) + \" seconds\")\n",
    "        times_search.append(search_time/10)\n",
    "        print(\"____________________________________________________\")\n",
    "    plt.title(\"insert and search with bloom filter of varrying size\")\n",
    "    plt.xlabel(\"size of filter\", labelpad=10)\n",
    "    plt.ylabel(\"time in seconds\")\n",
    "    plt.plot([int(i) for i in sizes], times_insert, label=\"insert\")\n",
    "    plt.plot([int(i) for i in sizes], times_search, label=\"search\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def test_bloom_hashes(): #Testing performance of bloom filter with different number of hash functions\n",
    "    data_generator= TestDataGenerator()\n",
    "    number = [str(i) for i in range(1,1000,100)]\n",
    "    times_insert=[]\n",
    "    times_search=[]\n",
    "    list = data_generator.generateData(1000)\n",
    "    search_list = list.copy()\n",
    "    random.shuffle(search_list)\n",
    "    for size in number:\n",
    "        bf = BloomFilterSettest(int(size), 100000)\n",
    "        insert_time = timeit.timeit(lambda: insert(bf, list), number=iterations)\n",
    "        times_insert.append(insert_time/iterations)\n",
    "        print(\"Inserting into bloom filter with \" + size + \" hashes \"+\" took \" + str(insert_time/iterations) + \" seconds\")\n",
    "        search_time = timeit.timeit(lambda: search(bf,search_list), number=10)\n",
    "        print(\"Searching into bloom filter with \" + size + \" hashes \"+\" took \" + str(search_time/10) + \" seconds\")\n",
    "        times_search.append(search_time/10)\n",
    "        print(\"____________________________________________________\")\n",
    "    plt.title(\"insert and search with bloom filter of varrying number of hashes\")\n",
    "    plt.xlabel(\"number of hashes\")\n",
    "    plt.ylabel(\"time in seconds\")\n",
    "    plt.plot([int(i) for i in number], times_insert, label=\"insert\")\n",
    "    plt.plot([int(i) for i in number], times_search, label= \"search\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "test_bloom_size()\n",
    "test_bloom_hashes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
